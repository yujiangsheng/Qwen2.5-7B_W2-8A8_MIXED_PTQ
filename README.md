# Qwen2.5-7B æ··åˆç²¾åº¦é‡åŒ–é¡¹ç›®

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.9+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg" alt="PyTorch">
  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">
  <img src="https://img.shields.io/badge/Platform-macOS%20|%20Linux%20|%20Windows-lightgrey.svg" alt="Platform">
</p>

åŸºäºé—ä¼ ç®—æ³•ä¼˜åŒ–çš„æ··åˆç²¾åº¦åè®­ç»ƒé‡åŒ–ï¼ˆMixed-Precision PTQï¼‰æ¡†æ¶ï¼Œä¸“é—¨é’ˆå¯¹ **Qwen2.5-7B-Instruct** å¤§è¯­è¨€æ¨¡å‹è®¾è®¡ã€‚

---

## ğŸ“– ç›®å½•

- [é¡¹ç›®æ¦‚è¿°](#-é¡¹ç›®æ¦‚è¿°)
- [æ ¸å¿ƒç‰¹æ€§](#-æ ¸å¿ƒç‰¹æ€§)
- [é‡è¦æ¦‚å¿µ](#-é‡è¦æ¦‚å¿µæ¨¡æ‹Ÿé‡åŒ–-vs-çœŸå®é‡åŒ–)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„)
- [ä½¿ç”¨æŒ‡å—](#-ä½¿ç”¨æŒ‡å—)
- [å‘½ä»¤è¡Œå‚æ•°](#-å‘½ä»¤è¡Œå‚æ•°)
- [æŠ€æœ¯åŸç†](#-æŠ€æœ¯åŸç†)
- [æ€§èƒ½å¯¹æ¯”](#-æ€§èƒ½å¯¹æ¯”)
- [å¸¸è§é—®é¢˜](#-å¸¸è§é—®é¢˜)
- [å‚è€ƒæ–‡çŒ®](#-å‚è€ƒæ–‡çŒ®)

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„æ··åˆç²¾åº¦é‡åŒ–å·¥ä½œæµï¼š

1. **æ™ºèƒ½é…ç½®æœç´¢**ï¼šä½¿ç”¨é—ä¼ ç®—æ³•ä¸ºæ¯ä¸€å±‚æ‰¾åˆ°æœ€ä¼˜çš„é‡åŒ–ä½å®½ (W2/W4/W8)
2. **æ•æ„Ÿåº¦åˆ†æ**ï¼šè‡ªåŠ¨è¯†åˆ«å¯¹é‡åŒ–æ•æ„Ÿçš„å±‚ï¼Œé‡‡ç”¨ä¿å®ˆç­–ç•¥
3. **GGUF å¯¼å‡º**ï¼šå°†é…ç½®å¯¼å‡ºä¸º llama.cpp å…¼å®¹çš„ GGUF æ ¼å¼
4. **æ€§èƒ½å¯¹æ¯”**ï¼šä¸åŸå§‹æ¨¡å‹å’Œç»Ÿä¸€é‡åŒ–æ¨¡å‹è¿›è¡Œå…¨é¢å¯¹æ¯”

---

## âœ¨ æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| ğŸ§¬ **é—ä¼ ç®—æ³•ä¼˜åŒ–** | å…¨å±€æœç´¢æœ€ä¼˜çš„é€å±‚ä½å®½é…ç½®ï¼Œé¿å…å±€éƒ¨æœ€ä¼˜ |
| ğŸ¯ **æ··åˆç²¾åº¦é‡åŒ–** | æ•æ„Ÿå±‚ W8ï¼Œæ™®é€šå±‚ W4ï¼Œéæ•æ„Ÿå±‚ W2 |
| ğŸ”§ **SmoothQuant** | é€šè¿‡æ¿€æ´»å€¼å¹³æ»‘å‡å°‘é‡åŒ–è¯¯å·® |
| ğŸ“¦ **GGUF å¯¼å‡º** | å®Œå…¨å…¼å®¹ llama.cpp çš„çœŸå®é‡åŒ–æ¨ç† |
| âš¡ **å¤šè®¾å¤‡æ”¯æŒ** | CUDA / MPS (Apple Silicon) / CPU |
| ğŸ“Š **å®Œæ•´è¯„ä¼°** | é€Ÿåº¦ã€è´¨é‡ã€å†…å­˜çš„å…¨é¢å¯¹æ¯”åˆ†æ |

---

## âš ï¸ é‡è¦æ¦‚å¿µï¼šæ¨¡æ‹Ÿé‡åŒ– vs çœŸå®é‡åŒ–

åœ¨ä½¿ç”¨æœ¬é¡¹ç›®ä¹‹å‰ï¼Œè¯·åŠ¡å¿…ç†è§£è¿™ä¸¤ç§é‡åŒ–æ–¹å¼çš„**æœ¬è´¨åŒºåˆ«**ï¼š

### ğŸ”¬ æ¨¡æ‹Ÿé‡åŒ– (Simulated Quantization)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ¨¡æ‹Ÿé‡åŒ–æµç¨‹ï¼ˆæœ¬é¡¹ç›®çš„ mixed_precision_ptq.pyï¼‰                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   FP32 æƒé‡ â”€â”€â†’ é‡åŒ–(round) â”€â”€â†’ åé‡åŒ– â”€â”€â†’ FP32 æƒé‡(æœ‰æŸå¤±)    â”‚
â”‚                                                                 â”‚
â”‚   â€¢ è®¡ç®—ä»ç„¶æ˜¯ FP32ï¼Œåªæ˜¯æ¨¡æ‹Ÿä½ç²¾åº¦å¸¦æ¥çš„ç²¾åº¦æŸå¤±               â”‚
â”‚   â€¢ âŒ ä¸ä¼šåŠ é€Ÿï¼Œåè€Œå› ä¸ºé¢å¤–æ“ä½œå˜æ…¢                            â”‚
â”‚   â€¢ âœ… ç”¨äºè¯„ä¼°é‡åŒ–å¯¹æ¨¡å‹ç²¾åº¦çš„å½±å“                              â”‚
â”‚   â€¢ âœ… ç”¨äºæœç´¢æœ€ä¼˜çš„é‡åŒ–é…ç½®                                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸš€ çœŸå®é‡åŒ– (Real Quantization)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  çœŸå®é‡åŒ–æµç¨‹ï¼ˆllama.cpp / bitsandbytes / TensorRTï¼‰            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   FP32 æƒé‡ â”€â”€â†’ è½¬æ¢ä¸º INT4/INT8 â”€â”€â†’ å­˜å‚¨ä¸º GGUF æ ¼å¼           â”‚
â”‚                                                                 â”‚
â”‚   â€¢ è®¡ç®—ç›´æ¥ä½¿ç”¨ä½ç²¾åº¦æ•´æ•°è¿ç®—ï¼ˆç¡¬ä»¶åŠ é€Ÿï¼‰                      â”‚
â”‚   â€¢ âœ… çœŸæ­£åŠ é€Ÿæ¨ç†ï¼ˆ5-10xï¼‰                                     â”‚
â”‚   â€¢ âœ… å¤§å¹…å‡å°‘å†…å­˜å ç”¨ï¼ˆ70-85%ï¼‰                                â”‚
â”‚   â€¢ âœ… é€‚åˆç”Ÿäº§éƒ¨ç½²                                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Š å®æµ‹æ€§èƒ½å¯¹æ¯”

| æ–¹å¼ | åŸå§‹æ¨¡å‹ (FP16) | æ¨¡æ‹Ÿé‡åŒ– | çœŸå®é‡åŒ– (Q4_K_M) | æ··åˆç²¾åº¦ GGUF |
|------|-----------------|----------|-------------------|---------------|
| **æ¨ç†é€Ÿåº¦** | 14.7 tok/s | 0.8 tok/s âŒ | 68.5 tok/s âœ… | 53.5 tok/s âœ… |
| **å†…å­˜å ç”¨** | ~14.2 GB | ~14.2 GB | 4.36 GB âœ… | 8.54 GB âœ… |
| **å‹ç¼©æ¯”** | 1.0x | 1.0x | 3.3x | 1.7x |
| **ç”¨é€”** | åŸºå‡† | é…ç½®æœç´¢ | ç”Ÿäº§éƒ¨ç½² | ç”Ÿäº§éƒ¨ç½² |

> ğŸ’¡ **ç»“è®º**ï¼šæƒ³è¦çœŸæ­£çš„åŠ é€Ÿæ•ˆæœï¼Œå¿…é¡»ä½¿ç”¨**çœŸå®é‡åŒ–**ï¼

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/your-username/Qwen2.5-7B_W2-8A8_MIXED_PTQ.git
cd Qwen2.5-7B_W2-8A8_MIXED_PTQ

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install -r requirements.txt

# å®‰è£… llama-cpp-pythonï¼ˆç”¨äºçœŸå®é‡åŒ–æ¨ç†ï¼‰
# macOS (Metal åŠ é€Ÿ)
CMAKE_ARGS="-DLLAMA_METAL=on" pip install llama-cpp-python

# Linux/Windows (CUDA åŠ é€Ÿ)
CMAKE_ARGS="-DLLAMA_CUDA=on" pip install llama-cpp-python
```

### 2. ä¸‹è½½é¢„é‡åŒ–æ¨¡å‹

```bash
# ä¸‹è½½ Q4_K_M é‡åŒ–æ¨¡å‹ï¼ˆ4.36 GBï¼‰
huggingface-cli download bartowski/Qwen2.5-7B-Instruct-GGUF \
    Qwen2.5-7B-Instruct-Q4_K_M.gguf --local-dir models
```

### 3. è¿è¡Œå¯¹æ¯”æµ‹è¯•

```bash
# å¿«é€Ÿå¯¹æ¯”æµ‹è¯•ï¼ˆæ¨èï¼ï¼‰
python compare_real_quant.py --max_tokens 200

# å®Œæ•´ä¸‰æ¨¡å‹å¯¹æ¯”
python compare_three_models.py --max_tokens 200
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
Qwen2.5-7B_W2-8A8_MIXED_PTQ/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                     # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python ä¾èµ–
â”œâ”€â”€ ğŸ“„ .gitignore                    # Git å¿½ç•¥è§„åˆ™
â”‚
â”œâ”€â”€ ğŸ”§ ã€æ ¸å¿ƒæ¨¡å—ã€‘
â”œâ”€â”€ quant_utils.py                   # é‡åŒ–æ ¸å¿ƒå‡½æ•°åº“
â”‚   â”œâ”€â”€ quantize_tensor()            #   - å¼ é‡é‡åŒ–å‡½æ•°
â”‚   â”œâ”€â”€ SmoothQuantLinear            #   - SmoothQuant çº¿æ€§å±‚
â”‚   â””â”€â”€ MixedPrecisionLinear         #   - æ··åˆç²¾åº¦çº¿æ€§å±‚
â”‚
â”œâ”€â”€ genetic_optim.py                 # é—ä¼ ç®—æ³•ä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ MixedPrecisionGA             #   - é—ä¼ ç®—æ³•ä¸»ç±»
â”‚   â”œâ”€â”€ LayerSensitivityAnalyzer     #   - å±‚æ•æ„Ÿåº¦åˆ†æ
â”‚   â””â”€â”€ fitness_function()           #   - é€‚åº”åº¦è¯„ä¼°å‡½æ•°
â”‚
â”œâ”€â”€ data_utils.py                    # æ•°æ®å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ get_calib_dataset()          #   - åŠ è½½æ ¡å‡†æ•°æ®é›†
â”‚   â””â”€â”€ create_mock_input()          #   - åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥
â”‚
â”œâ”€â”€ âš™ï¸ ã€ä¸»ç¨‹åºã€‘
â”œâ”€â”€ mixed_precision_ptq.py           # æ··åˆç²¾åº¦é‡åŒ–ä¸»ç¨‹åº
â”‚                                    #   - æ•æ„Ÿåº¦åˆ†æ
â”‚                                    #   - é—ä¼ ç®—æ³•æœç´¢
â”‚                                    #   - é…ç½®ä¿å­˜
â”‚
â”œâ”€â”€ export_gguf_official.py          # GGUF æ ¼å¼å¯¼å‡º
â”‚                                    #   - ä½¿ç”¨å®˜æ–¹ gguf åº“
â”‚                                    #   - ç”Ÿæˆ llama.cpp å…¼å®¹æ ¼å¼
â”‚
â”œâ”€â”€ ğŸ§ª ã€æµ‹è¯•è„šæœ¬ã€‘
â”œâ”€â”€ test_mixed_precision.py          # æ¨¡æ‹Ÿé‡åŒ–æ¨ç†æµ‹è¯•
â”œâ”€â”€ compare_models.py                # æ¨¡æ‹Ÿé‡åŒ– vs åŸå§‹æ¨¡å‹
â”œâ”€â”€ compare_real_quant.py            # çœŸå®é‡åŒ– vs åŸå§‹æ¨¡å‹
â””â”€â”€ compare_three_models.py          # ä¸‰æ¨¡å‹å…¨é¢å¯¹æ¯”
â”‚
â”œâ”€â”€ ğŸ“¦ ã€è¾“å‡ºæ–‡ä»¶ã€‘
â”œâ”€â”€ mixed_precision_config.pt        # é‡åŒ–é…ç½®ï¼ˆæ¯å±‚ä½å®½ï¼‰
â””â”€â”€ models/                          # æ¨¡å‹æ–‡ä»¶ç›®å½•
    â”œâ”€â”€ Qwen2.5-7B-Instruct-Q4_K_M.gguf  # Q4_K_M ç»Ÿä¸€é‡åŒ–
    â””â”€â”€ qwen2.5-7b-mixed.gguf            # æ··åˆç²¾åº¦é‡åŒ–
```

---

## ğŸ“– ä½¿ç”¨æŒ‡å—

### æ–¹æ¡ˆ Aï¼šå®Œæ•´å·¥ä½œæµï¼ˆæ¨èï¼‰

é€‚åˆæƒ³è¦è‡ªå®šä¹‰é‡åŒ–é…ç½®çš„ç”¨æˆ·ã€‚

```bash
# ç¬¬1æ­¥ï¼šè¿è¡Œæ··åˆç²¾åº¦æœç´¢ï¼ˆçº¦ 30-60 åˆ†é’Ÿï¼‰
python mixed_precision_ptq.py \
    --device mps \              # æˆ– cuda
    --ga_gen 15 \               # é—ä¼ ç®—æ³•ä»£æ•°
    --target_compression 0.25   # ç›®æ ‡å‹ç¼©æ¯”

# ç¬¬2æ­¥ï¼šå¯¼å‡ºä¸º GGUF æ ¼å¼ï¼ˆçº¦ 5 åˆ†é’Ÿï¼‰
python export_gguf_official.py \
    --output models/qwen2.5-7b-mixed.gguf

# ç¬¬3æ­¥ï¼šè¿è¡Œä¸‰æ¨¡å‹å¯¹æ¯”æµ‹è¯•
python compare_three_models.py --max_tokens 200
```

### æ–¹æ¡ˆ Bï¼šå¿«é€Ÿä½“éªŒ

é€‚åˆåªæƒ³ä½“éªŒçœŸå®é‡åŒ–æ•ˆæœçš„ç”¨æˆ·ã€‚

```bash
# ä¸‹è½½é¢„é‡åŒ–æ¨¡å‹
huggingface-cli download bartowski/Qwen2.5-7B-Instruct-GGUF \
    Qwen2.5-7B-Instruct-Q4_K_M.gguf --local-dir models

# è¿è¡ŒçœŸå®é‡åŒ–å¯¹æ¯”
python compare_real_quant.py --max_tokens 200
```

---

## âŒ¨ï¸ å‘½ä»¤è¡Œå‚æ•°

### mixed_precision_ptq.py

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--model_id` | `Qwen/Qwen2.5-7B-Instruct` | HuggingFace æ¨¡å‹ ID |
| `--device` | è‡ªåŠ¨æ£€æµ‹ | è®¡ç®—è®¾å¤‡ï¼š`cuda`ã€`mps`ã€`cpu` |
| `--ga_pop` | 20 | é—ä¼ ç®—æ³•ç§ç¾¤å¤§å° |
| `--ga_gen` | 12 | é—ä¼ ç®—æ³•è¿­ä»£ä»£æ•° |
| `--target_compression` | 0.25 | ç›®æ ‡å‹ç¼©æ¯” (0.25 = 25%) |
| `--output` | `mixed_precision_config.pt` | è¾“å‡ºé…ç½®æ–‡ä»¶è·¯å¾„ |

### compare_three_models.py

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--model_id` | `Qwen/Qwen2.5-7B-Instruct` | åŸå§‹æ¨¡å‹ ID |
| `--q4km_path` | `models/Qwen2.5-7B-Instruct-Q4_K_M.gguf` | Q4_K_M æ¨¡å‹è·¯å¾„ |
| `--mixed_path` | `models/qwen2.5-7b-mixed.gguf` | æ··åˆç²¾åº¦æ¨¡å‹è·¯å¾„ |
| `--max_tokens` | 200 | æœ€å¤§ç”Ÿæˆ token æ•° |
| `--skip_original` | False | è·³è¿‡åŸå§‹æ¨¡å‹æµ‹è¯• |

### compare_real_quant.py

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--model_id` | `Qwen/Qwen2.5-7B-Instruct` | åŸå§‹æ¨¡å‹ ID |
| `--gguf_path` | `models/Qwen2.5-7B-Instruct-Q4_K_M.gguf` | GGUF æ¨¡å‹è·¯å¾„ |
| `--max_tokens` | 200 | æœ€å¤§ç”Ÿæˆ token æ•° |

### export_gguf_official.py

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--model_id` | `Qwen/Qwen2.5-7B-Instruct` | åŸå§‹æ¨¡å‹ ID |
| `--config` | `mixed_precision_config.pt` | é‡åŒ–é…ç½®æ–‡ä»¶ |
| `--output` | `models/qwen2.5-7b-mixed.gguf` | è¾“å‡º GGUF è·¯å¾„ |

---

## ğŸ”¬ æŠ€æœ¯åŸç†

### 1. æ··åˆç²¾åº¦ç­–ç•¥

ä¸åŒç±»å‹çš„å±‚å¯¹é‡åŒ–çš„æ•æ„Ÿåº¦ä¸åŒï¼š

| å±‚ç±»å‹ | æ•æ„Ÿåº¦ | æ¨èä½å®½ | åŸå›  |
|--------|--------|----------|------|
| Attention Q/K | é«˜ | W8 | å½±å“æ³¨æ„åŠ›è®¡ç®—ç²¾åº¦ |
| Attention V/O | ä¸­ | W4 | ä¿¡æ¯ä¼ é€’å±‚ |
| FFN Gate/Up | ä¸­ | W4 | æ¿€æ´»å‡½æ•°ç›¸å…³ |
| FFN Down | ä½ | W2-W4 | è¾“å‡ºæŠ•å½±å±‚ |
| Embedding | ä½ | W2-W4 | è¯åµŒå…¥æŸ¥è¡¨ |
| LayerNorm | é«˜ | FP32 | å½’ä¸€åŒ–éœ€è¦é«˜ç²¾åº¦ |

### 2. é—ä¼ ç®—æ³•ä¼˜åŒ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é—ä¼ ç®—æ³•æœç´¢æœ€ä¼˜ä½å®½é…ç½®                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1. åˆå§‹åŒ–ï¼šéšæœºç”Ÿæˆ N ä¸ªä½å®½é…ç½®ï¼ˆæŸ“è‰²ä½“ï¼‰                   â”‚
â”‚       æ¯ä¸ªæŸ“è‰²ä½“ = [layer0_bits, layer1_bits, ..., layerN]   â”‚
â”‚                                                              â”‚
â”‚  2. é€‚åº”åº¦è¯„ä¼°ï¼š                                              â”‚
â”‚       fitness = Î± Ã— (1/MSE) + Î² Ã— å‹ç¼©ç‡                     â”‚
â”‚       MSE = é‡åŒ–å‰åè¾“å‡ºçš„å‡æ–¹è¯¯å·®                            â”‚
â”‚                                                              â”‚
â”‚  3. é€‰æ‹©ï¼šé”¦æ ‡èµ›é€‰æ‹©ï¼Œä¿ç•™ä¼˜ç§€ä¸ªä½“                            â”‚
â”‚                                                              â”‚
â”‚  4. äº¤å‰ï¼šå•ç‚¹äº¤å‰äº§ç”Ÿå­ä»£                                    â”‚
â”‚       çˆ¶ä»£A: [4,4,8,2,4,8,...]                                â”‚
â”‚       çˆ¶ä»£B: [8,4,4,4,2,4,...]                                â”‚
â”‚                    â†“ äº¤å‰ç‚¹                                   â”‚
â”‚       å­ä»£:  [4,4,8|4,2,4,...]                                â”‚
â”‚                                                              â”‚
â”‚  5. å˜å¼‚ï¼šéšæœºæ”¹å˜éƒ¨åˆ†åŸºå›                                     â”‚
â”‚       [4,4,8,4,2,4,...] â†’ [4,4,8,8,2,4,...]                   â”‚
â”‚                                                              â”‚
â”‚  6. è¿­ä»£ï¼šé‡å¤ 2-5 ç›´åˆ°æ”¶æ•›æˆ–è¾¾åˆ°æœ€å¤§ä»£æ•°                     â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. SmoothQuant æŠ€æœ¯

å°†æ¿€æ´»å€¼çš„é‡åŒ–éš¾åº¦è½¬ç§»åˆ°æƒé‡ï¼Œä½¿ä¸¤è€…æ›´å®¹æ˜“é‡åŒ–ï¼š

```python
# åŸå§‹è®¡ç®—
Y = X @ W

# SmoothQuant å˜æ¢
s = (max|X|^Î±) / (max|W|^(1-Î±))  # Î±=0.5 æ—¶å¹³è¡¡
X' = X / s      # æ¿€æ´»å€¼ç¼©å°
W' = W * s      # æƒé‡æ”¾å¤§
Y = X' @ W'     # ç»“æœä¸å˜ï¼Œä½†ä¸¤è€…éƒ½æ›´æ˜“é‡åŒ–
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

åœ¨ Apple M4 Max (Metal) ä¸Šçš„æµ‹è¯•ç»“æœï¼š

| æ¨¡å‹ | å¤§å° | åŠ è½½æ—¶é—´ | æ¨ç†é€Ÿåº¦ | å†…å­˜å ç”¨ |
|------|------|----------|----------|----------|
| åŸå§‹ (FP16) | ~14.2 GB | ~3s | 14.7 tok/s | ~30 GB |
| Q4_K_M | 4.36 GB | ~1s | **68.5 tok/s** | ~5 GB |
| æ··åˆç²¾åº¦ | 8.54 GB | ~2s | 53.5 tok/s | ~9 GB |

**å…³é”®æŒ‡æ ‡ï¼š**
- Q4_K_M æ¯”åŸå§‹æ¨¡å‹å¿« **4.7x**
- Q4_K_M å†…å­˜å‡å°‘ **83%**
- æ··åˆç²¾åº¦æ¯”åŸå§‹æ¨¡å‹å¿« **3.6x**

---

## â“ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆæ¨¡æ‹Ÿé‡åŒ–åæ¨ç†æ›´æ…¢äº†ï¼Ÿ

**A**: è¿™æ˜¯æ­£å¸¸çš„ï¼æ¨¡æ‹Ÿé‡åŒ–åœ¨ FP32 åŸºç¡€ä¸Šå¢åŠ äº†é¢å¤–çš„è®¡ç®—ï¼ˆscale/clamp/roundï¼‰ï¼Œåªæ˜¯æ¨¡æ‹Ÿç²¾åº¦æŸå¤±ï¼Œä¸ä¼šåŠ é€Ÿã€‚æƒ³è¦åŠ é€Ÿå¿…é¡»ç”¨**çœŸå®é‡åŒ–**ã€‚

### Q2: å¦‚ä½•è·å¾—çœŸæ­£çš„åŠ é€Ÿæ•ˆæœï¼Ÿ

**A**: ä½¿ç”¨çœŸå®é‡åŒ–ï¼š
```bash
python compare_real_quant.py --max_tokens 200
```

### Q3: MPS è®¾å¤‡æŠ¥é”™æ€ä¹ˆåŠï¼Ÿ

**A**: 
1. ç¡®ä¿ä½¿ç”¨ `torch.float32` ç²¾åº¦ï¼ˆMPS å¯¹ FP16 æ”¯æŒæœ‰é™ï¼‰
2. æ›´æ–° PyTorch åˆ°æœ€æ–°ç‰ˆæœ¬
3. å¯¹äº llama.cppï¼Œç¡®ä¿ç¼–è¯‘æ—¶å¯ç”¨ Metalï¼š
   ```bash
   CMAKE_ARGS="-DLLAMA_METAL=on" pip install llama-cpp-python --force-reinstall
   ```

### Q4: é‡åŒ–åè¾“å‡ºä¹±ç æˆ–è´¨é‡ä¸‹é™ï¼Ÿ

**A**: W2 å±‚è¿‡å¤šå¯èƒ½å¯¼è‡´ç²¾åº¦æŸå¤±ã€‚è°ƒæ•´ç›®æ ‡å‹ç¼©æ¯”ï¼š
```bash
python mixed_precision_ptq.py --target_compression 0.35
```

### Q5: è¾“å‡ºçš„å¥å­ä¸å®Œæ•´ï¼Ÿ

**A**: è¿™æ˜¯ **token æ•°é‡é™åˆ¶**é—®é¢˜ï¼Œä¸æ˜¯é‡åŒ–è´¨é‡é—®é¢˜ã€‚å¢åŠ  `--max_tokens`ï¼š
```bash
python compare_three_models.py --max_tokens 300
```

### Q6: å¦‚ä½•åªæµ‹è¯• GGUF æ¨¡å‹ï¼ˆä¸åŠ è½½åŸå§‹æ¨¡å‹ï¼‰ï¼Ÿ

**A**: ä½¿ç”¨ `--skip_original` å‚æ•°èŠ‚çœå†…å­˜ï¼š
```bash
python compare_three_models.py --skip_original --max_tokens 200
```

---

## ğŸ’» ç¡¬ä»¶è¦æ±‚

| è®¾å¤‡ | æœ€ä½è¦æ±‚ | æ¨èé…ç½® |
|------|----------|----------|
| **CUDA GPU** | 16GB VRAM | 24GB+ VRAM (A100/4090) |
| **Apple Silicon** | M1 16GB | M2 Pro 32GB+ |
| **CPU** | 32GB RAM | 64GB+ RAM |

> ğŸ’¡ å¯¹äº Apple Siliconï¼Œæ¨èä½¿ç”¨ Metal åŠ é€Ÿï¼š
> ```bash
> CMAKE_ARGS="-DLLAMA_METAL=on" pip install llama-cpp-python
> ```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

- [SmoothQuant: Accurate and Efficient Post-Training Quantization](https://arxiv.org/abs/2211.10438)
- [GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers](https://arxiv.org/abs/2210.17323)
- [AWQ: Activation-aware Weight Quantization](https://arxiv.org/abs/2306.00978)
- [Qwen2.5 Technical Report](https://github.com/QwenLM/Qwen2.5)
- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [GGUF Format Specification](https://github.com/ggerganov/ggml/blob/master/docs/gguf.md)

---

## ğŸ“„ License

æœ¬é¡¹ç›®é‡‡ç”¨ MIT License å¼€æºåè®®ã€‚

---

## ğŸ‘¤ ä½œè€…

**Jiangsheng Yu**

- GitHub: [@yujiangsheng](https://github.com/yujiangsheng)

---

<p align="center">
  å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ Starï¼
</p>
